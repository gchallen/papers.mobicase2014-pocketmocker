\begin{abstract}
Smartphones represent the most serious threat to user privacy of any
widely-deployed computing technology. Today millions of people voluntarily
carry an always-on, observant, powerful, and connected device with them at
all times. This provides onboard smartphone apps with an ideal vantage point
from which to invade users' personal lives. Unfortunately, existing
permission models provide smartphone users with limited protection, in part
due to the difficulty to users in distinguishing between legitimate and
illegitimate use their data. A mapping app may upload the same location
information it uses to download maps (legitimate) to a marketing agency
interested in delivering location-based ads (illegitimate), while a pedometer
processes the same accelerometer data it uses to count steps (legitimate) to
determine the user's weight (illegitimate). As a result, smartphone users
find themselves forced to make burdensome and error-prone tradeoffs between
app functionality and privacy.

We propose a new approach, called DataDecoy. Instead of trying
to limit apps' access to user data, DataDecoy turns apps' interest in data
collection against them. By allowing substitution of real data streams with
artificial or \textit{mocked} data, DataDecoy allows users to manipulate
impressions of their behavior in well-defined ways: to appear more fit, more
social, or more on-time than they actually are. Instead of focusing on
privacy, we explore providing users with an amount of management over their
smartphone-derived digital identities that echos the control they already
possess when using online tools such as social networks. We discuss the
design of DataDecoy, which uses user-initiated context trace recording and
replay to enable objective-driven context mocking. Our evaluation shows that
users want to use DataDecoy, that DataDecoy can mock popular smartphone apps,
and that DataDecoy is usable.
\end{abstract}
