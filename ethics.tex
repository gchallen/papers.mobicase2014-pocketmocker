\section{Ethical and Practical Issues}
\label{sec-ethics}

Objective-based context mocking raises a set of unique ethical questions
related to the relationship between smartphone users and apps, as well as a
set of practical deployment challenges. We attempt to address both in this
section. Even if not widely-deployed, we hope that the availability of this
feature will help create a useful dialogue about smartphone data collection
and user privacy.

\subsection{Is Mocking Cheating?}

A common reaction by many to mocking is to conflate it with cheating, given
that it involves misleading apps about a users true nature. This response,
however, begs the question: what are the rules of the game? Cheating must be
defined with respect to an agreement, and we are not convinced that users
have actually agreed to provide an unlimited amount of information about
their personal lives to smartphone apps. While installing an app does involve
allowing it to access certain information, we believe that it is reasonable
for users to expect that apps request information required by the features
they provide and use it only to provide those features. Unfortunately,
particularly once the information leaves the device, users quickly lose
control over how their data is used. Mocking can help return this control.

Another common objection is that the current smartphone app ecosystem depends
on collecting user information in order to subsidize app development, most
commonly by using personal information to embed targeted advertisements in
apps, and that users benefit from lower app prices as a result. There are two
problems with this argument. First, as mentioned earlier smartphone users
have indicated on surveys that they are not comfortable with this model of
subsidizing apps through personal data collection. Second, believing that
this model is really a good deal for smartphone users requires them to trust
the same companies that are actively trying to monetize this information. A
sense that they are not receiving adequate compensation for personal
information may drive expressed discomfort with this business model. In any
case, because smartphone users have different privacy concerns and
expectations, not every user should be required to trade their data for
access to apps.

\subsection{Is Mocking Safe?}

A more serious concern with mocking concerns the effect it might have on
apps, particularly ones that are health-related. If mocking confuses an app
designed to remind a user to take a pill, it could have serious health
consequences. Here it is important to distinguish between the possible
side-effects of mocking on legitimate apps and the intentional effect of
mocking on apps that the user is intending to mislead. For example, if a
doctor asks a patient who wants to get fit to install a pedometer to help
increase their activity level and the patient chooses to mislead this app
with mocked activities, then the main problem is not really the mocking
capability. If the user wants the app to help them become healthier, they
will cooperate with it; if not, they can always refuse to be monitored
altogether or find another doctor. Here mocking is not needed to provide
users with control over their personal information.

To preserve the correct operation of safety-critical apps that might be
confused by context mocking, \PocketMocker{} already provides users the
ability to allow certain apps to always receive real data. As we develop more
experience with our \PocketMocker{} prototype we will focus on refining this
mechanism more carefully and ensuring that it is effective. Additional
interaction with apps could be helpful. For example, future version of
\PocketMocker{} may allow apps to issue a request to not be mocked, which the
user could approve or ignore, helping remind users to adjust mocking settings
as new apps are installed.

\subsection{Can Mocking Be Deployed?}

\PocketMocker{} requires platform support. Given the locked-down nature of
major smartphone platforms today, this means that deploying
\PocketMocker{} requires the cooperation of the companies such as Google,
Apple, and Microsoft that maintain the dominant three smartphone platforms
available today\footnote{Because their platforms are closed-source, Apple and
Microsoft would have to implement this feature themselves. We are preparing a
patch for Google's Android Open Source Project.}. Unfortunately, we expect
that all smartphone platform providers have an interest in perpetuating the
exposure of personal information to apps that \PocketMocker{} is intended to
frustrate, making them unwilling to implement mocking. 

There are two potential ways around this roadblock. First, we will explore
integrating mocking into popular third-party Android platform distributions
such as CyanogenMod, which provides alternative ROMs to users interested in
replacing their stock Android image by rooting their phone. While this
community is small, they may be disproportionately interested in mocking
given their willingness to void their warranties and the intentions of
smartphone device manufactures. Even a small number of users using
\PocketMocker{} could lead the smartphone privacy conversation in the right
direction. Second, at some point smartphones may be required to provide more
configurability at the platform level to support apps, similar to the way
that desktop operating systems allow apps to install device drivers. This
feature would allow \PocketMocker{} to make required platform changes.

\subsection{What Effect Would Mocking Have?}

Finally, we consider the effect that \PocketMocker{} would have on smartphone
data collection and privacy if deployed on a significant number of devices.
First, we would expect to see an interest among app developers in deploying
countermeasures to detect or eliminate mocked data. We have already discussed
protecting the mocking device against attacks launched from apps running on
the device and how the mocking context on Android can be secured through
modifications to the Linux kernel. A more difficult or impossible set of
attacks are launched by colluding with other devices or with surrounding
infrastructure. Interdevice collusion is more feasible, since it could be
launched by cooperating instances of the same app. In certain cases
\PocketMocker{} could mock cross-device interaction to fool the local app, or
simply disable interfaces such as Bluetooth allowing device-to-device
communication.

Collusion with the infrastructure would represent a more serious challenge to
our approach. As an example, if mobile data networks began reporting
smartphone user's location directly to app providers apps could use this
information to pierce the mocking context by comparing the location being
reported to them by \PocketMocker{} to infrastructure-reported location.
Usage statistics also visible to infrastructure providers could also be used
to determine when \PocketMocker{} was mocking a Wifi connection at particular
location but actually running connections across the mobile data network.
While this type of collusion is the most effective way to shut down our
mocking approach, it would also represent an unprecedented level of cooperation
between network providers and the companies selling apps and services. We
anticipate that these types of agreements would be highly-unattractive to
smartphone users already concerned about their privacy.

Our ultimate hope is developing objective-driven context mocking is to
initiate a conversation about what our personal data is worth. Today, because
smartphone users lack effective tools to control the data they provide to
apps, they are effectively surrendering their personal information without
receiving anything in return. So while this data is clearly worth something,
as evidenced by advertisers scrambling to develop novel location-based
analytics, as long as we give it away for free we will never know how much.
If mocking causes apps to begin to be suspicious of the personal data they
can collect, this may help make legitimate information about users valuable
again.
